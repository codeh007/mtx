import { streamText as aiSdkStreamText, convertToCoreMessages } from "ai";
// import { getLlmOpenaiClient } from "./llm_config";

interface ToolResult<Name extends string, Args, Result> {
  toolCallId: string;
  toolName: Name;
  args: Args;
  result: Result;
}

interface Message {
  role: "user" | "assistant";
  content: string;
  toolInvocations?: ToolResult<string, unknown, unknown>[];
}

export type Messages = Message[];

export type StreamingOptions = Omit<
  Parameters<typeof aiSdkStreamText>[0],
  "model"
>;

export async function streamTextV2(
  messages: Messages,
  env,
  systemPrompt?: string,
  options?: StreamingOptions,
) {
  const openaiModel = getLlmOpenaiClient();

  const result = await aiSdkStreamText({
    model: openaiModel,
    system: systemPrompt,
    messages: convertToCoreMessages(messages as []),
    ...options,
  });
  return result;
}
