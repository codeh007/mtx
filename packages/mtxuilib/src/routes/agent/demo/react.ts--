import { PromptTemplate } from "@langchain/core/prompts";
import { OpenAI } from "@langchain/openai";
import { Hono } from "hono";
import { AgentExecutor, createReactAgent } from "langchain/agents";
import { llmGet, promptGet } from "mtmaiapi";
import type { Env } from "../../../types";
export const reactAgentDemoRoute = new Hono<{ Bindings: Env }>()
  // .get("/", async (c) => {
  //   return c.json({
  //     message: "react agent demo 请使用 post 方法",
  //   });
  // })
  .get("/", async (c) => {
    try {
      // const body = await c.req.parseBody();

      // const llm = new OpenAI({
      //   model: "gpt-3.5-turbo-instruct",
      //   temperature: 0,
      // });

      // Get the prompt to use - you can modify this!
      // If you want to see the prompt in full, you can at:
      // https://smith.langchain.com/hub/hwchase17/react
      // const prompt = await pull<PromptTemplate>("hwchase17/react");

      const promptText = await promptGet({
        path: {
          prompt: "react-chat",
          tenant: "default",
        },
      });
      if (!promptText.data) {
        return c.json({
          message: "promptText.data is undefined",
        });
      }

      const llmConfig = await llmGet({
        path: {
          slug: "default",
          tenant: "default",
        },
        //@ts-expect-error
        body: {},
      });

      if (!llmConfig.data) {
        return c.json({
          message: "llmConfig.data is undefined",
        });
      }

      const tools = [];
      const llm = new OpenAI({
        model: llmConfig.data.model,
        // temperature: llmConfig.temperature,
      });

      const ptpl = PromptTemplate.fromTemplate(promptText.data);
      const agent = await createReactAgent({
        llm,
        tools,
        //@ts-ignore
        prompt: ptpl,
      });

      const agentExecutor = new AgentExecutor({
        agent,
        tools: [],
      });

      // See public LangSmith trace here: https://smith.langchain.com/public/d72cc476-e88f-46fa-b768-76b058586cc1/r
      const result = await agentExecutor.invoke({
        input: "what is LangChain?",
      });

      console.log(result);

      // Get the prompt to use - you can modify this!
      // If you want to see the prompt in full, you can at:
      // https://smith.langchain.com/hub/hwchase17/react-chat
      // const promptWithChat = await pull<PromptTemplate>("hwchase17/react-chat");

      // const agentWithChat = await createReactAgent({
      //   llm,
      //   tools,
      //   prompt: promptWithChat,
      // });

      const agentExecutorWithChat = new AgentExecutor({
        //@ts-ignore
        agent: agentWithChat,
        tools,
      });

      const result2 = await agentExecutorWithChat.invoke({
        input: "what's my name?",
        // Notice that chat_history is a string, since this prompt is aimed at LLMs, not chat models
        chat_history:
          "Human: Hi! My name is Cob\nAI: Hello Cob! Nice to meet you",
      });
      //@ts-expect-error
      return new Response(twiml, {
        headers: {
          "Content-Type": "application/xml",
        },
      });
    } catch (e: any) {
      return c.json({
        error: e.message,
      });
    }
  });
